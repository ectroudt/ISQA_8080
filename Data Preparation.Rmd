---
title: "Data Preparation"
author: "Dr. Christian Haas"
date: "August 27, 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# R Data Preparation

This is an overview of how to conduct standard data preparation in R. We will consider variable preparation through centering and standardization, as well as dealing with missing observations.


## Handling NAs and Imputation

Handling missing values is one of the most common things we need to do with 'real' data. Here, we discuss two options:
for categorical data, we can simply add 'NA' as separate factor level (or, add the separate 'missing' category). For regression tasks, we can try to 'fill' the missing pieces through a process called 'imputation'.

Note: if you want to combine this with resampling such as cross-validation, you need to make sure to run the imputation only on the training sets and not the test sets, otherwise you could 'leak' information to the test set and thus overestimate the actual model performance.

The caret package supports several versions of imputation, such as random forests, knn, or median imputation.

```{r imputation}

# set your working directory to the current file directory 
tryCatch({
  setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
  }, error=function(cond){message(paste("cannot change working directory"))
})


# we also load a package for a systematic and clean interface to build machine learning models
library(caret)
library(tidyverse)
data <- read_csv("CollegeGraduationRates_Imputation.csv")

# we can see that we have a bunch of missing values
summary(data)

# Option 1: categorical variables
# we have the Private variable which is binary: Yes / No
# we replace the NAs for categorical variables with a 'missing' factor level
# dataset <- dataset %>% mutate_if(is.factor, addNA, ifany=TRUE)
dataset <- data %>% mutate_if(is.character, ~factor(replace(as.character(.), is.na(.), "missing")))

# check if the missing categorical variables were added correctly
summary(dataset)

## Option 2: numerical variables. should only be performed on the numerical variables
library(RANN) # this defines different imputation methods

target_var <- 'Grad.Rate'
model_form <- Grad.Rate ~ .
model_type <- 'lm'

trainIndex <- createDataPartition(dataset[[target_var]], p = 0.8, list = FALSE)
data_train <- dataset[trainIndex,]
data_test <- dataset[-trainIndex,]

# For the categorical variables, we 'learn' the imputation on the training set and then apply this on the test set to avoid leakage. 
data_train_num <- data_train %>% select_if(is.numeric)
data_train_non_num <- data_train %>% select_if(~!is.numeric(.x))
data_test_num <- data_test %>% select_if(is.numeric)
data_test_non_num <- data_test %>% select_if(~!is.numeric(.x))

# note: in the current implementation, knnImpute does automatic scaling which might not be desired
pre_proc_impute_knn <- preProcess(data_train_num, method = "knnImpute", k = 5)
data_train_imputed_knn <- cbind(data_train_non_num, predict(pre_proc_impute_knn, data_train_num))
summary(data_train_imputed_knn)
data_test_imputed_knn <- cbind(data_test_non_num, predict(pre_proc_impute_knn, data_test_num))

pre_proc_impute_bag <- preProcess(data_train_num, method = "bagImpute") # this will take longer
data_train_imputed_bag <- cbind(data_train_non_num, predict(pre_proc_impute_bag, data_train_num))
summary(data_train_imputed_bag)
data_test_imputed_bag <- cbind(data_test_non_num, predict(pre_proc_impute_bag, data_test_num))

# For the categorical variables, we 'learn' the imputation on the training set and then apply this on the test set to avoid leakage. 
data_train_num <- data_train %>% select_if(is.numeric)
data_train_non_num <- data_train %>% select_if(~!is.numeric(.x))
data_test_num <- data_test %>% select_if(is.numeric)
data_test_non_num <- data_test %>% select_if(~!is.numeric(.x))

#### ALternative, not stable approach
# note: in the current implementation, knnImpute does automatic scaling which might not be desired
# specify the preprocessing steps, in this case, the imputation via bagImpute
library(recipes)
recipe <- recipe(model_form, data = data_train)
recipe_imputation <- recipe %>% step_bagimpute(all_numeric()) # impute the missing numerical variables
recipe_imputation <- recipe %>% step_knnimpute(all_numeric()) # impute the missing numerical variables
recipe_imputation <- recipe %>% step_medianimpute(all_numeric()) # impute the missing numerical variables


# we will use a 10-fold cross validation on the training set to select the best complexity parameter
trControl <- trainControl(method = 'repeatedcv', repeats = 3, number = 10, savePredictions = TRUE)

# note: we will handle the imputation of numerical variables inside the train() function
# this guarantees that no imputation information is 'leaked' into the test sets.
lm_model <- train(recipe_imputation, data = data_train, method = model_type, trControl = trControl)

lm_model

# predicting the test set
lm_test_pred <- lm_model %>% predict(newdata = data_test)

postResample(lm_test_pred, data_test[[target_var]])


# compare against the imputation before the cross validation:
lm_model_alternative <- train(model_form, data = data_train_imputed_bag, method = model_type, trControl = trControl)

lm_model_alternative

# predicting the test set
lm_test_alternative_pred <- lm_model_alternative %>% predict(newdata = data_test_imputed_bag)

postResample(lm_test_alternative_pred, data_test[[target_var]])


# Alternative 2: specify the pre-process directly in the train() function. Be aware that this can be very time/resource intensive!
lm_model_alternative_2 <- caret::train(model_form, data = data_train, method = model_type, trControl = trControl, preProcess = 'bagImpute', na.action = na.pass)
lm_model_alternative_2

# predicting the test set
lm_test_alternative_2_pred <- lm_model_alternative_2 %>% predict(newdata = data_test, na.action = na.pass)

postResample(lm_test_alternative_2_pred, data_test[[target_var]])

```

## Centering, Standardizing, Normalizing

In many cases, using input variables on their original scale might not be the best solution. For example, certain models such as KNN use distance-based metrics and thus are sensitive to scale magnitues. In other cases, SVMs often converge faster when the data is centered and standardized first.

Fortunately, with the help of the caret package these steps can be easily implemented. Note: We will talk about more features of the caret package in the future templates. 

```{r data_prep}
# first, load some required libraries
library(MASS) # large collection of data sets and functions
library(ISLR)
library(pROC)
source("../Utils.R")

set.seed(1)
heart <- read_csv("Heart.csv")
data <- prepare_heart(heart)

target_var <- "AHD"
model_form <- AHD ~ Age + Sex + RestBP + Chol + Ca
model_type <- 'knn'
positive_class <- "Yes"

# let's do a basic training-test split
trainIndex <- createDataPartition(data[[target_var]], p = 0.7, list = FALSE)
data_train <- data[trainIndex,]
data_test <- data[-trainIndex,]

# let's start by fitting the model with the original variables
trControl <- trainControl(method = 'none', savePredictions = TRUE, classProbs = TRUE)

knn_fit <- train(as.formula(model_form), data = data_train, method = model_type, trControl = trControl)

# we can also use the predict function again to predict new outcomes
knn_pred_class <- knn_fit %>%  predict(type ='raw', newdata = data_test) # this assumes a threshold of 0.5
knn_pred_probs <- knn_fit %>% predict(type = 'prob', newdata = data_test)

# confusion matrix
confusionMatrix(knn_pred_class, data_test[[target_var]], positive = positive_class)

# ROC curve
roc(data_test[[target_var]], knn_pred_probs[,positive_class], plot = TRUE, print.auc = TRUE, legacy.axes = TRUE)

## then, let's center and scale them
# we can do this by specifying the following pre-processing step

# option 1: we can manually create the datasets

data_standardize <- preProcess(data_train, method = c("center", "scale")) # scaling is dividing by the standard deviation. combining centering and scaling is equal to standardizing

data_train_standardized <- predict(data_standardize, data_train)
data_test_standardized <- predict(data_standardize, data_test)

knn_fit_standardized <- train(as.formula(model_form), data = data_train_standardized, method = model_type, trControl = trControl)

# we can also use the predict function again to predict new outcomes
knn_pred_class_standardized <- knn_fit_standardized %>%  predict(type ='raw', newdata = data_test_standardized) # this assumes a threshold of 0.5
knn_pred_probs_standardized <- knn_fit_standardized %>% predict(type = 'prob', newdata = data_test_standardized)

# confusion matrix
confusionMatrix(knn_pred_class_standardized, data_test_standardized[[target_var]], positive = positive_class)

# ROC curve
roc(data_test_standardized[[target_var]], knn_pred_probs_standardized[,positive_class], plot = TRUE, print.auc = TRUE, legacy.axes = TRUE)

# option 2: we can also just give the pre-process information to our training function
knn_fit_standardized <- train(as.formula(model_form), data = data_train, method = model_type, trControl = trControl, preProc = c("center", "scale"))

# we can also use the predict function again to predict new outcomes
knn_pred_class_standardized <- knn_fit_standardized %>%  predict(type ='raw', newdata = data_test) # this assumes a threshold of 0.5
knn_pred_probs_standardized <- knn_fit_standardized %>% predict(type = 'prob', newdata = data_test)

# confusion matrix
confusionMatrix(knn_pred_class_standardized, data_test[[target_var]], positive = positive_class)

# ROC curve
roc(data_test[[target_var]], knn_pred_probs_standardized[,positive_class], plot = TRUE, print.auc = TRUE, legacy.axes = TRUE)

### Normalization
# we can also use normalization, i.e., converting the numerical variables onto a [0,1] scale
knn_fit_normalized <- train(as.formula(model_form), data = data_train, method = model_type, trControl = trControl, preProc = c("range"))

# we can also use the predict function again to predict new outcomes
knn_pred_class_normalized <- knn_fit_normalized %>%  predict(type ='raw', newdata = data_test) # this assumes a threshold of 0.5
knn_pred_probs_normalized <- knn_fit_normalized %>% predict(type = 'prob', newdata = data_test)

# confusion matrix
confusionMatrix(knn_pred_class_normalized, data_test[[target_var]], positive = positive_class)

# ROC curve
roc(data_test[[target_var]], knn_pred_probs_normalized[,positive_class], plot = TRUE, print.auc = TRUE, legacy.axes = TRUE)

```
